name: CI - Build and Test

# When to run this workflow
on:
  push:
    branches: [main]  # Run on push to main branch
  pull_request:
    branches: [main]  # Run on pull requests to main

# Jobs to execute
jobs:
  # Job 1: Lint and validate code (Matrix build - multiple Python versions)
  lint:
    name: Lint Python Code (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: ['3.10', '3.11', '3.12']  # Test 3 versions in parallel
      fail-fast: true  # Stop all matrix jobs if one fails
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff
          pip install -r services/customer_service/requirements.txt
      
      - name: Run linter (Ruff)
        run: |
          ruff check services/ --select E,F --ignore F401
        continue-on-error: true  # Don't fail pipeline, just warn
      
      - name: Test Python imports
        run: |
          python -c "import fastapi; import sqlalchemy; import pydantic; print('[OK] All imports successful')"

  # Job: Run unit tests with coverage
  test-unit:
    name: Unit Tests with Coverage
    runs-on: ubuntu-latest
    needs: lint  # Only run if lint passes
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r tests/requirements.txt
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --cov=services --cov-report=xml --cov-report=term
      
      - name: Upload coverage to GitHub
        run: |
          echo "## Unit Test Coverage" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          coverage report --format=markdown >> $GITHUB_STEP_SUMMARY || echo "Coverage report generation failed" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  # Job 2: Build Docker images (disabled - requires Docker Hub auth in CI)
  # build:
  #   name: Build Docker Images
  #   runs-on: ubuntu-latest
  #   
  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4
  #     
  #     - name: Set up Docker Buildx
  #       uses: docker/setup-buildx-action@v3
  #     
  #     - name: Build customer-service image
  #       uses: docker/build-push-action@v5
  #       with:
  #         context: .
  #         file: ./docker/Dockerfile.customer_service
  #         push: false  # Don't push yet, just validate build
  #         tags: fintegrate-customer-service:test
  #     
  #     - name: Build event-consumer image
  #       uses: docker/build-push-action@v5
  #       with:
  #         context: .
  #         file: ./docker/Dockerfile.event_consumer
  #         push: false
  #         tags: fintegrate-event-consumer:test

  # Job 3: Test with multiple PostgreSQL versions
  test-postgres:
    name: Test with PostgreSQL ${{ matrix.postgres-version }}
    runs-on: ubuntu-latest
    needs: test-unit  # Only run if unit tests pass
    
    strategy:
      matrix:
        postgres-version: ['13', '14', '15', '16']  # Test 4 PostgreSQL versions
      fail-fast: true  # Stop all if one fails
    
    services:
      postgres:
        image: postgres:${{ matrix.postgres-version }}
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install psycopg2-binary sqlalchemy
      
      - name: Test PostgreSQL connection
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/test_db
        run: |
          python -c "
          from sqlalchemy import create_engine, text
          engine = create_engine('$DATABASE_URL')
          with engine.connect() as conn:
              result = conn.execute(text('SELECT version()'))
              version = result.fetchone()[0]
              print(f'✅ Connected to PostgreSQL: {version}')
          "
      
      - name: Test table creation
        env:
          DATABASE_URL: postgresql://test_user:test_pass@localhost:5432/test_db
        run: |
          python -c "
          from sqlalchemy import create_engine, text
          engine = create_engine('$DATABASE_URL')
          with engine.connect() as conn:
              conn.execute(text('CREATE TABLE IF NOT EXISTS test_table (id SERIAL PRIMARY KEY, name VARCHAR(100))'))
              conn.execute(text('INSERT INTO test_table (name) VALUES (\\'Test\\')'))
              conn.commit()
              result = conn.execute(text('SELECT * FROM test_table'))
              print(f'✅ Table operations successful: {result.fetchone()}')
          "

  # Job 4: Test on multiple operating systems (simplified)
  test-multi-os:
    name: Test on ${{ matrix.os }}
    runs-on: ${{ matrix.os }}
    
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]  # Test 3 OS
        python-version: ['3.11']
      fail-fast: false  # Continue testing all OS even if one fails
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r services/customer_service/requirements.txt
      
      - name: Test Python imports (cross-platform)
        run: |
          python -c "import fastapi; import sqlalchemy; import pydantic; print('[OK] All imports successful on ${{ matrix.os }}')"

  # Job 5: Validate Kubernetes manifests
  validate-k8s:
    name: Validate Kubernetes Manifests
    runs-on: ubuntu-latest
    needs: lint  # Run in parallel with tests after lint
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Validate YAML syntax
        run: |
          # Check if YAML files are valid (supports multi-document files)
          find kubernetes/ -name "*.yaml" -o -name "*.yml" | while read file; do
            echo "Validating $file"
            python -c "import yaml; list(yaml.safe_load_all(open('$file')))" || exit 1
          done
      
      - name: Generate deployment summary
        run: |
          echo "# Kubernetes Deployment Summary" > deployment-summary.md
          echo "" >> deployment-summary.md
          echo "**Generated**: $(date)" >> deployment-summary.md
          echo "" >> deployment-summary.md
          echo "## Deployments" >> deployment-summary.md
          find kubernetes/deployments -name "*.yaml" -exec basename {} \; >> deployment-summary.md
          echo "" >> deployment-summary.md
          echo "## Services" >> deployment-summary.md
          find kubernetes/services -name "*.yaml" -exec basename {} \; >> deployment-summary.md
      
      - name: Upload deployment summary artifact
        uses: actions/upload-artifact@v4
        with:
          name: deployment-summary
          path: deployment-summary.md
          retention-days: 30

  # Job 6: Generate test report artifacts
  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [test-unit, test-postgres]  # Run after all tests complete
    if: always()  # Run even if tests fail (to generate failure report)
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-html pytest-cov
          pip install -r services/customer_service/requirements.txt
      
      - name: Create test results directory
        run: mkdir -p test-results
      
      - name: Run tests with coverage
        run: |
          # Run pytest (will create empty report even if no tests exist)
          pytest tests/ \
            --html=test-results/test-report.html \
            --self-contained-html \
            --cov=services \
            --cov-report=html:test-results/coverage \
            --cov-report=term \
            || echo "No tests found - creating placeholder report"
        continue-on-error: true
      
      - name: Create test summary
        run: |
          echo "# Test Execution Summary" > test-results/summary.md
          echo "" >> test-results/summary.md
          echo "**Date**: $(date)" >> test-results/summary.md
          echo "**Branch**: ${{ github.ref_name }}" >> test-results/summary.md
          echo "**Commit**: ${{ github.sha }}" >> test-results/summary.md
          echo "" >> test-results/summary.md
          echo "## Test Files" >> test-results/summary.md
          find tests/ -name "test_*.py" >> test-results/summary.md || echo "No test files found" >> test-results/summary.md
      
      - name: Upload test report artifact
        uses: actions/upload-artifact@v4
        with:
          name: test-report
          path: test-results/
          retention-days: 90
      
      - name: Upload coverage report artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: test-results/coverage/
          retention-days: 30
        continue-on-error: true
